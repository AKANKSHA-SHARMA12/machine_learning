{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Remove all the punctuations, symbols, emojis and\n",
    "    unwanted characters from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = re.sub('[^a-zA-Z]', ' ', dataset['Review'][0])\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Get all the data in similar case. Lower case is \n",
    "    preferred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow    loved this place '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp.lower()\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Remove all the unwanted words like prepositions, \n",
    "    conjunctions, pronouns, determiners etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'this', 'place']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp.split()\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'place']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [word for word in temp \n",
    " if not word in set(stopwords.words('english'))]\n",
    "t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Stemming ya Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'love', 'place']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = [ps.stem(word) for word in temp \n",
    " if not word in set(stopwords.words('english'))]\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(t, t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [ps.stem(word) for word in temp \n",
    " if not word in set(stopwords.words('english'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ' '.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = []\n",
    "\n",
    "for i in range(1000):\n",
    "    temp = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    temp = temp.lower()\n",
    "    temp = temp.split()\n",
    "    temp = [ps.stem(word) for word in temp \n",
    " if not word in set(stopwords.words('english'))]\n",
    "    temp = ' '.join(temp)\n",
    "    clean_reviews.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 500)\n",
    "X = cv.fit_transform(clean_reviews)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Liked'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X, y)\n",
    "knn.fit(X, y)\n",
    "dtf.fit(X, y)\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X, y)\n",
    "knn.score(X, y)\n",
    "dtf.score(X, y)\n",
    "nb.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolut', 'actual', 'ago', 'also', 'although', 'alway', 'amaz', 'ambianc', 'ambienc', 'amount', 'anoth', 'anytim', 'anyway', 'appet', 'area', 'around', 'arriv', 'ask', 'ate', 'atmospher', 'attent', 'authent', 'averag', 'avoid', 'aw', 'away', 'awesom', 'back', 'bacon', 'bad', 'bar', 'bare', 'bartend', 'bathroom', 'bay', 'bean', 'beat', 'beauti', 'beef', 'beer', 'believ', 'belli', 'best', 'better', 'big', 'bill', 'biscuit', 'bit', 'bite', 'bland', 'boot', 'bother', 'boy', 'boyfriend', 'bread', 'break', 'breakfast', 'brick', 'bring', 'brought', 'brunch', 'buck', 'buffet', 'bug', 'build', 'burger', 'busi', 'butter', 'bye', 'cafe', 'call', 'came', 'care', 'check', 'chees', 'chef', 'chewi', 'chicken', 'chip', 'clean', 'close', 'cold', 'come', 'complet', 'consid', 'contain', 'cook', 'cool', 'could', 'coupl', 'cours', 'cover', 'cream', 'crowd', 'custom', 'damn', 'day', 'deal', 'decid', 'decor', 'definit', 'delici', 'delight', 'delish', 'deserv', 'dessert', 'differ', 'dine', 'dinner', 'dirti', 'disappoint', 'disgust', 'dish', 'dog', 'done', 'door', 'dress', 'dri', 'drink', 'drive', 'duck', 'eat', 'eaten', 'edibl', 'egg', 'either', 'els', 'elsewher', 'empti', 'end', 'enjoy', 'enough', 'equal', 'especi', 'establish', 'even', 'ever', 'everi', 'everyon', 'everyth', 'excel', 'expect', 'experi', 'extrem', 'fact', 'fail', 'famili', 'fantast', 'far', 'fast', 'favorit', 'feel', 'felt', 'fill', 'final', 'find', 'fine', 'first', 'fish', 'flat', 'flavor', 'folk', 'food', 'found', 'fresh', 'fri', 'friend', 'friendli', 'frozen', 'full', 'fun', 'gave', 'gener', 'get', 'give', 'go', 'gone', 'good', 'got', 'great', 'greek', 'green', 'grill', 'gross', 'group', 'guess', 'guy', 'gyro', 'half', 'hand', 'happi', 'hard', 'hate', 'head', 'healthi', 'heart', 'help', 'high', 'highli', 'highlight', 'hit', 'home', 'homemad', 'honest', 'honestli', 'hope', 'horribl', 'hot', 'hour', 'hous', 'howev', 'huge', 'human', 'hummu', 'husband', 'ice', 'imagin', 'immedi', 'impress', 'incred', 'insid', 'insult', 'interest', 'job', 'judg', 'kept', 'kid', 'kind', 'know', 'known', 'lack', 'ladi', 'larg', 'last', 'late', 'later', 'least', 'leav', 'left', 'leg', 'legit', 'let', 'life', 'like', 'list', 'liter', 'littl', 'live', 'lobster', 'locat', 'long', 'look', 'lost', 'lot', 'love', 'lover', 'low', 'lunch', 'made', 'main', 'make', 'manag', 'mani', 'may', 'mayb', 'mayo', 'meal', 'mean', 'meat', 'mediocr', 'meh', 'melt', 'menu', 'mexican', 'mid', 'min', 'mind', 'minut', 'miss', 'mistak', 'mmmm', 'moist', 'mom', 'money', 'mouth', 'much', 'music', 'must', 'nasti', 'need', 'never', 'new', 'next', 'nice', 'night', 'none', 'noth', 'offer', 'oh', 'ok', 'old', 'one', 'option', 'order', 'outsid', 'outstand', 'overal', 'overpr', 'owner', 'pancak', 'paper', 'par', 'parti', 'pasta', 'patio', 'pay', 'peopl', 'perfect', 'perfectli', 'person', 'pho', 'phoenix', 'piec', 'pita', 'pizza', 'place', 'play', 'pleas', 'pleasant', 'point', 'poor', 'pork', 'portion', 'possibl', 'potato', 'prepar', 'pretti', 'price', 'probabl', 'provid', 'pull', 'qualiti', 'quick', 'quickli', 'quit', 'rare', 'rate', 'rather', 'real', 'realli', 'reason', 'receiv', 'recent', 'recommend', 'regular', 'restaur', 'return', 'review', 'rice', 'right', 'roast', 'roll', 'room', 'rude', 'run', 'sad', 'said', 'salad', 'salmon', 'salsa', 'salt', 'sandwich', 'sashimi', 'sat', 'satisfi', 'sauc', 'say', 'seafood', 'season', 'seat', 'second', 'see', 'seem', 'select', 'serious', 'serv', 'server', 'servic', 'set', 'sever', 'shop', 'shrimp', 'sick', 'side', 'sinc', 'sit', 'slice', 'slow', 'small', 'soggi', 'someon', 'someth', 'soon', 'soup', 'special', 'spend', 'spici', 'spot', 'staff', 'stale', 'star', 'stay', 'steak', 'step', 'still', 'stomach', 'stop', 'strip', 'style', 'subway', 'suck', 'super', 'sure', 'sushi', 'sweet', 'tabl', 'taco', 'take', 'talk', 'tast', 'tasteless', 'tasti', 'tea', 'tell', 'tender', 'terribl', 'textur', 'thai', 'thin', 'thing', 'think', 'though', 'thought', 'thumb', 'time', 'tip', 'toast', 'today', 'told', 'took', 'top', 'total', 'touch', 'town', 'treat', 'tri', 'trip', 'twice', 'two', 'unfortun', 'unless', 'us', 'use', 'vega', 'veget', 'vegetarian', 'vibe', 'visit', 'wait', 'waiter', 'waitress', 'walk', 'wall', 'want', 'warm', 'wast', 'watch', 'water', 'way', 'well', 'went', 'white', 'wife', 'wine', 'wing', 'wonder', 'word', 'work', 'world', 'wors', 'worst', 'worth', 'would', 'wow', 'wrap', 'wrong', 'year', 'yet', 'yummi', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3026 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 200)\n",
    "X = cv.fit_transform(clean_reviews)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "y = dataset['Liked'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtf = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X, y)\n",
    "knn.fit(X, y)\n",
    "dtf.fit(X, y)\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.721"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X, y)\n",
    "knn.score(X, y)\n",
    "dtf.score(X, y)\n",
    "nb.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolut', 'also', 'alway', 'amaz', 'ambianc', 'anoth', 'area', 'around', 'ask', 'atmospher', 'attent', 'awesom', 'back', 'bad', 'bar', 'bare', 'beer', 'best', 'better', 'bit', 'bland', 'breakfast', 'bring', 'buffet', 'burger', 'busi', 'came', 'check', 'chicken', 'chip', 'clean', 'cold', 'come', 'cook', 'could', 'custom', 'day', 'deal', 'definit', 'delici', 'dessert', 'dine', 'dinner', 'disappoint', 'dish', 'done', 'drink', 'eat', 'either', 'enjoy', 'enough', 'even', 'ever', 'everi', 'everyth', 'excel', 'expect', 'experi', 'famili', 'fantast', 'far', 'feel', 'felt', 'first', 'flavor', 'food', 'found', 'fresh', 'fri', 'friend', 'friendli', 'get', 'give', 'go', 'good', 'got', 'great', 'happi', 'help', 'hit', 'hot', 'hour', 'impress', 'insid', 'know', 'lack', 'last', 'like', 'littl', 'look', 'lot', 'love', 'lunch', 'made', 'make', 'manag', 'mani', 'meal', 'meat', 'mediocr', 'menu', 'minut', 'money', 'much', 'must', 'need', 'never', 'next', 'nice', 'night', 'noth', 'one', 'order', 'overal', 'overpr', 'owner', 'pasta', 'peopl', 'perfect', 'pizza', 'place', 'pleas', 'poor', 'portion', 'potato', 'pretti', 'price', 'probabl', 'qualiti', 'quit', 'rare', 'realli', 'reason', 'recommend', 'restaur', 'return', 'review', 'right', 'rude', 'said', 'salad', 'sandwich', 'sauc', 'say', 'seat', 'see', 'select', 'serious', 'serv', 'server', 'servic', 'side', 'sinc', 'slow', 'soon', 'special', 'spici', 'spot', 'staff', 'star', 'stay', 'steak', 'still', 'suck', 'super', 'sure', 'sushi', 'tabl', 'taco', 'take', 'talk', 'tast', 'tasti', 'tell', 'tender', 'terribl', 'thing', 'think', 'time', 'took', 'total', 'town', 'tri', 'twice', 'two', 'us', 'vega', 'wait', 'waiter', 'waitress', 'want', 'warm', 'wast', 'way', 'well', 'went', 'wonder', 'worst', 'worth', 'would']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
